version: v2
budget: ai2/oe-adapt
description: tulu2 7b ultrafeedback 13b openrlhf experiments
tasks:
- name: tulu2-7b-uf-13b-openrlhf-ppo
  image:
    beaker: mickell/openrlhf-torch2.3-cuda12.3-v2
  command: [ '/bin/sh', '-c' ]
  arguments: [
    "export CURRENT_DATETIME=$(date +%m%d%y_%H%M%S) && \
    echo CURRENT_DATETIME=$CURRENT_DATETIME && \
    cd $REPO_PATH && \
    python3 examples/train_ppo_ray.py \
    --ref_num_nodes 1 \
    --ref_num_gpus_per_node 1 \
    --reward_num_nodes 1 \
    --reward_num_gpus_per_node 1 \
    --critic_num_nodes 1 \
    --critic_num_gpus_per_node 1 \
    --actor_num_nodes 1 \
    --actor_num_gpus_per_node 1 \
    --vllm_num_engines 1 \
    --vllm_tensor_parallel_size 1 \
    --pretrain resources/models/tulu-2-7b \
    --critic_pretrain resources/models/UltraRM-13b \
    --reward_pretrain resources/models/UltraRM-13b \
    --save_path ckpt/tulu-2-7b-ppo-$CURRENT_DATETIME \
    --value_loss_coef 1.0 \
    --micro_train_batch_size 8 \
    --train_batch_size 128 \
    --micro_rollout_batch_size 8 \
    --rollout_batch_size 128 \
    --max_epochs 1 \
    --prompt_max_len 1024 \
    --generate_max_len 1024 \
    --rollout_temperature 0.7 \
    --zero_stage 2 \
    --actor_learning_rate 1e-6 \
    --critic_learning_rate 1e-6 \
    --init_kl_coef 0.01 \
    --prompt_data /train_dataset \
    --prompt_data_probs 1.0 \
    --actor_init_on_gpu \
    --gradient_checkpointing \
    --flash_attn \
    --bf16 \
    --save_steps 50 \
    --keep_latest \
    --adam_offload \
    --pad_token '<unk>' \
    --warmup_ratio 0.05 \
    --value_head_name regression_head \
    --use_wandb $WANDB_API_KEY \
    --wandb_run_name tulu-2-7b-ppo-v1.0 \
    --perf
    "
  ]
  envVars:
  - name: WANDB_API_KEY
    secret: WANDB_API_KEY
  - name: REPO_PATH
    value: /net/nfs.cirrascale/allennlp/mickell/code/OpenRLHF
  - name: PYTHONPATH
    value: /net/nfs.cirrascale/allennlp/mickell/code/OpenRLHF
  datasets:
  - mountPath: /net/nfs.cirrascale
    source:
      hostPath: /net/nfs.cirrascale
  - mountPath: /train_dataset
    source:
      beaker: mickell/ultrafeedback-binarized-preferences-cleaned
  result:
    path: '/output'
  resources:
    cpuCount: 32
    gpuCount: 5
  context:
    priority: normal 
  constraints:
    cluster: [ 
        ai2/allennlp-cirrascale,
        ai2/general-cirrascale-a100-80g-ib, 
      ]