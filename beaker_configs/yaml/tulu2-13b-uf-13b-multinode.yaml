version: v2
budget: ai2/oe-adapt
description: tulu2 13b ultrafeedback 13b openrlhf experiments
tasks:
- name: tulu2-13b-uf-13b-openrlhf-ppo-high-throughput
  replicas: 2
  leaderSelection: true
  hostNetworking: true
  propagateFailure: true
  synchronizedStartTimeout: 10m
  image:
    beaker: mickell/openrlhf-torch2.3-cuda12.3-v2
  command: [ '/bin/sh', '-c' ]
  arguments: [
    "cd $REPO_PATH && \
    source ./beaker_configs/ray_node_setup.sh && \
    python3 examples/train_ppo_ray.py \
    --ref_num_nodes 1 \
    --ref_num_gpus_per_node 2 \
    --reward_num_nodes 1 \
    --reward_num_gpus_per_node 2 \
    --critic_num_nodes 1 \
    --critic_num_gpus_per_node 4 \
    --actor_num_nodes 1 \
    --actor_num_gpus_per_node 4 \
    --vllm_num_engines 4 \
    --vllm_tensor_parallel_size 1 \
    --pretrain resources/models/tulu-2-13b \
    --critic_pretrain resources/models/UltraRM-13b \
    --reward_pretrain resources/models/UltraRM-13b \
    --save_path ckpt/tulu-2-13b-ppo-$CURRENT_DATETIME \
    --value_loss_coef 1.0 \
    --micro_train_batch_size 16 \
    --train_batch_size 128 \
    --micro_rollout_batch_size 8 \
    --rollout_batch_size 128 \
    --max_epochs 1 \
    --prompt_max_len 1024 \
    --generate_max_len 1024 \
    --rollout_temperature 0.7 \
    --zero_stage 2 \
    --actor_learning_rate 1e-6 \
    --critic_learning_rate 1e-6 \
    --init_kl_coef 0.025 \
    --prompt_data /train_dataset \
    --prompt_data_probs 1.0 \
    --actor_init_on_gpu \
    --gradient_checkpointing \
    --flash_attn \
    --bf16 \
    --save_steps 50 \
    --keep_latest \
    --adam_offload \
    --pad_token '<unk>' \
    --warmup_ratio 0.05 \
    --value_head_name regression_head \
    --use_wandb $WANDB_API_KEY \
    --wandb_run_name tulu-2-13b-ppo-v115"
  ]
  envVars:
  - name: WANDB_API_KEY
    secret: WANDB_API_KEY
  - name: REPO_PATH
    value: /net/nfs.cirrascale/allennlp/mickell/code/OpenRLHF
  datasets:
  - mountPath: /net/nfs.cirrascale
    source:
      hostPath: /net/nfs.cirrascale
  - mountPath: /train_dataset
    source:
      beaker: mickell/ultrafeedback-binarized-preferences-cleaned
  result:
    path: '/output'
  resources:
    gpuCount: 8
  context:
    priority: normal 
  constraints:
    cluster: [ 
      ai2/jupiter-cirrascale,
      ai2/pluto-cirrascale
      # ai2/jupiter-cirrascale
        # ai2/allennlp-cirrascale 
        # ai2/general-cirrascale-a100-80g-ib, 
      ]